{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# physical_devices = tf.config.list_physical_devices(\"GPU\")\n",
    "# tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train = x_train.reshape(-1, 28, 28, 1).astype(\"float32\") / 255.0\n",
    "x_test = x_test.reshape(-1, 28, 28, 1).astype(\"float32\") / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CNN architecture fundamental CNN->Batchnorm->ReLU. If we want to code for 10 layers then it is not convenient to write same code multiple times for different layers. Instead we can define a class for the model and use it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNBlock(layers.Layer):\n",
    "    def __init__(self, out_channels, kernel_size=3):\n",
    "        super(CNNBlock, self).__init__()\n",
    "        self.conv = layers.Conv2D(out_channels, kernel_size, padding=\"same\")\n",
    "        self.bn = layers.BatchNormalization()\n",
    "\n",
    "    def call(self, input_tensor, training=False):      \n",
    "        x = self.conv(input_tensor)\n",
    "        x = self.bn(x, training=training)\n",
    "        x = tf.nn.relu(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE**\n",
    "- out_channels=number of filters: refers to depth of the convolutional layers\n",
    "- self.conv : defines a conv layer\n",
    "- def call : main forward pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResBlock(layers.Layer):\n",
    "    def __init__(self, channels):\n",
    "        super(ResBlock, self).__init__()\n",
    "        self.channels = channels\n",
    "        self.cnn1 = CNNBlock(channels[0], 3)\n",
    "        self.cnn2 = CNNBlock(channels[1], 3)\n",
    "        self.cnn3 = CNNBlock(channels[2], 3)\n",
    "        self.pooling = layers.MaxPooling2D()\n",
    "        self.identity_mapping = layers.Conv2D(channels[1], 3, padding=\"same\")\n",
    "\n",
    "    def call(self, input_tensor, training=False):\n",
    "        x = self.cnn1(input_tensor, training=training)\n",
    "        x = self.cnn2(x, training=training)\n",
    "        x = self.cnn3(x + self.identity_mapping(input_tensor), training=training,)\n",
    "        x = self.pooling(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE**\n",
    "- channels : is a list of 3 integers representing the output size of 3 CNN layers\n",
    "- identity_mapping: this is the main part of understanding of this block of code.\n",
    "  - The purpose of self.identity_mapping in the ResBlock is to introduce an identity shortcut connection. By this shortcut connection we have a several advantages.\n",
    "    - It adds the input tensors with the output of the second cnn. this addition actually tells us the difference between the input and the second cnn output. By this difference check the model have the chance to check if the residual features are retained. $output= Input + Residual$. here, residual is the difference. By adding the residual, the network \"corrects\" the output and ensures that the relevant information is preserved.\n",
    "    - The term \"shortcut\" comes from the fact that this connection provides a shortcut for the gradient during backpropagation, allowing it to flow more easily through the network. In traditional deep networks, as the number of layers increases, the gradients can diminish (vanishing gradient) or explode (exploding gradient) as they propagate backward during training. This makes training deeper networks more challenging. With the shortcut connection, the gradients during backpropagation can directly \"shortcut\" through the identity mapping (the addition operation) without being affected by the convolutional layers. The addition operation creates a \"skip connection\" that enables the gradient to flow directly from the output to the input of cnn2, effectively bypassing cnn1 and cnn3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet_Like(keras.Model):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(ResNet_Like, self).__init__()\n",
    "        self.block1 = ResBlock([32, 32, 64])\n",
    "        self.block2 = ResBlock([128, 128, 256])\n",
    "        self.block3 = ResBlock([128, 256, 512])\n",
    "        self.pool = layers.GlobalAveragePooling2D()  #layers.Flatten()\n",
    "        self.classifier = layers.Dense(num_classes)\n",
    "\n",
    "    def call(self, input_tensor, training=False):\n",
    "        x = self.block1(input_tensor, training=training)\n",
    "        x = self.block2(x, training=training)\n",
    "        x = self.block3(x, training=training)\n",
    "        x = self.pool(x, training=training)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "    def model(self):\n",
    "        x = keras.Input(shape=(28, 28, 1))\n",
    "        return keras.Model(inputs=[x], outputs=self.call(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE**\n",
    "- this is Model like ResNet, not exactly!\n",
    "- Global Average Pooling 2D reduces the spatial dimensions of the tensor to a single value per channel by averaging the values across the spatial dimensions. This is often used as an alternative to traditional flattening before the final classification layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ResNet_Like().model()\n",
    "base_input = model.layers[0].input\n",
    "base_output = model.layers[2].output\n",
    "output = layers.Dense(10)(layers.Flatten()(base_output))\n",
    "model = keras.Model(base_input, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(),\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "938/938 - 590s - loss: 0.1025 - accuracy: 0.9680 - 590s/epoch - 629ms/step\n",
      "157/157 - 19s - loss: 0.0308 - accuracy: 0.9905 - 19s/epoch - 122ms/step\n",
      "INFO:tensorflow:Assets written to: pretrained\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: pretrained\\assets\n"
     ]
    }
   ],
   "source": [
    "model.fit(x_train, y_train, batch_size=64, epochs=1, verbose=2)\n",
    "model.evaluate(x_test, y_test, batch_size=64, verbose=2)\n",
    "model.save(\"pretrained\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
