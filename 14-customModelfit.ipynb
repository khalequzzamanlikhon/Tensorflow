{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train = x_train.reshape(-1, 28, 28, 1).astype(\"float32\") / 255.0\n",
    "x_test = x_test.reshape(-1, 28, 28, 1).astype(\"float32\") / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential(\n",
    "    [\n",
    "        layers.Input(shape=(28, 28, 1)),\n",
    "        layers.Conv2D(64, (3, 3), padding=\"same\"),\n",
    "        layers.ReLU(),\n",
    "        layers.Conv2D(128, (3, 3), padding=\"same\"),\n",
    "        layers.ReLU(),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(10),\n",
    "    ],\n",
    "    name=\"model\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 28, 28, 64)        640       \n",
      "                                                                 \n",
      " re_lu (ReLU)                (None, 28, 28, 64)        0         \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 28, 28, 128)       73856     \n",
      "                                                                 \n",
      " re_lu_1 (ReLU)              (None, 28, 28, 128)       0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 100352)            0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 10)                1003530   \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1078026 (4.11 MB)\n",
      "Trainable params: 1078026 (4.11 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class CustomFit(keras.Model):\n",
    "    def __init__(self, model):\n",
    "        super(CustomFit, self).__init__()\n",
    "        self.model = model\n",
    "\n",
    "    def compile(self, optimizer, loss):\n",
    "        super(CustomFit, self).compile()\n",
    "        self.optimizer = optimizer\n",
    "        self.loss = loss\n",
    "\n",
    "    def train_step(self, data):\n",
    "        x, y = data\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            # Caclulate predictions\n",
    "            y_pred = self.model(x, training=True)\n",
    "\n",
    "            # Loss\n",
    "            loss = self.loss(y, y_pred)\n",
    "\n",
    "        # Gradients\n",
    "        training_vars = self.trainable_variables\n",
    "        gradients = tape.gradient(loss, training_vars)\n",
    "\n",
    "        # Step with optimizer\n",
    "        self.optimizer.apply_gradients(zip(gradients, training_vars))\n",
    "        acc_metric.update_state(y, y_pred)\n",
    "\n",
    "        return {\"loss\": loss, \"accuracy\": acc_metric.result()}\n",
    "\n",
    "    def test_step(self, data):\n",
    "        # Unpack the data\n",
    "        x, y = data\n",
    "\n",
    "        # Compute predictions\n",
    "        y_pred = self.model(x, training=False)\n",
    "\n",
    "        # Updates the metrics tracking the loss\n",
    "        loss = self.loss(y, y_pred)\n",
    "\n",
    "        # Update the metrics.\n",
    "        acc_metric.update_state(y, y_pred)\n",
    "        return {\"loss\": loss, \"accuracy\": acc_metric.result()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- compile method of the CustomFit class is used to specify the optimizer and loss function to be used during training. This method is overridden from the parent class (keras.Model). The overridden method is calling the parent method to ensure proper compilation.\n",
    "- A tf.GradientTape context is created to record the operations that involve calculating gradients.\n",
    "- The optimizer's apply_gradients method is used to update the model's trainable variables based on the calculated gradients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "acc_metric = keras.metrics.SparseCategoricalAccuracy(name=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "training = CustomFit(model)\n",
    "training.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=3e-4),\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- creating a instance of custom model class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "938/938 - 186s - loss: 0.0392 - accuracy: 0.9489 - 186s/epoch - 198ms/step\n",
      "Epoch 2/2\n",
      "938/938 - 188s - loss: 0.2251 - accuracy: 0.9658 - 188s/epoch - 201ms/step\n",
      "157/157 - 7s - loss: 0.0028 - accuracy: 0.9673 - 7s/epoch - 42ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.9673230648040771, 0.0028109289705753326]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training.fit(x_train, y_train, batch_size=64, epochs=2,verbose=2)\n",
    "training.evaluate(x_test, y_test, batch_size=64,verbose=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
