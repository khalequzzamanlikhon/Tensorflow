{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# physical_devices = tf.config.list_physical_devices(\"GPU\")\n",
    "# tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train = x_train.reshape(-1, 28, 28, 1).astype(\"float32\") / 255.0\n",
    "x_test = x_test.reshape(-1, 28, 28, 1).astype(\"float32\") / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CNN architecture fundamental CNN->Batchnorm->ReLU. If we want to code for 10 layers then it is not convenient to write same code multiple times for different layers. Instead we can define a class for the model and use it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNBlock(layers.Layer):\n",
    "    def __init__(self, out_channels, kernel_size=3): \n",
    "        super(CNNBlock, self).__init__()\n",
    "        self.conv = layers.Conv2D(out_channels, kernel_size, padding=\"same\")\n",
    "        self.bn = layers.BatchNormalization()\n",
    "\n",
    "    def call(self, input_tensor, training=False):      \n",
    "        x = self.conv(input_tensor)\n",
    "        x = self.bn(x, training=training)\n",
    "        x = tf.nn.relu(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE**\n",
    "- CNNBlock calss inherits keras.layers.Layer\n",
    "- __init__ constructor. here behaviour of the layer can be defined. when an object of this class is instantiated we need to pass the out_channels and kernel_size.\n",
    "- super is the parent class constructor which defines the layer properly\n",
    "- out_channels=number of filters: refers to depth of the convolutional layers\n",
    "- self.conv : defines a conv layer\n",
    "- def call : main forward pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResBlock(layers.Layer):\n",
    "    def __init__(self, channels):\n",
    "        super(ResBlock, self).__init__()\n",
    "        self.channels = channels\n",
    "        self.cnn1 = CNNBlock(channels[0], 3)\n",
    "        self.cnn2 = CNNBlock(channels[1], 3)\n",
    "        self.cnn3 = CNNBlock(channels[2], 3)\n",
    "        self.pooling = layers.MaxPooling2D()\n",
    "        self.identity_mapping = layers.Conv2D(channels[1], 3, padding=\"same\")\n",
    "\n",
    "    def call(self, input_tensor, training=False):\n",
    "        x = self.cnn1(input_tensor, training=training)\n",
    "        x = self.cnn2(x, training=training)\n",
    "        x = self.cnn3(x + self.identity_mapping(input_tensor), training=training,)\n",
    "        x = self.pooling(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE**\n",
    "\n",
    "**Resnet analogy**:\n",
    "Imagine you're an artist trying to fix a painting that isn't quite what you want it to be. You start with an initial version of the painting that you're not entirely satisfied with. However, instead of starting from scratch, you decide to make incremental adjustments to improve it. This way, you preserve the parts that are already good while focusing on correcting the areas that need improvement.\n",
    "\n",
    "**Explanation**: the input tensor is like the initial image. then after conv1,conv2 layer the output is compared with the input tensor and get the residual features which is actually the differences between output of second conv and input tensors.\n",
    "\n",
    "\n",
    "\n",
    "- channels : is a list of 3 integers representing the output size of 3 CNN layers\n",
    "- identity_mapping: this is the main part of understanding of this block of code.\n",
    "  - The purpose of self.identity_mapping in the ResBlock is to introduce an identity shortcut connection. By this shortcut connection we have a several advantages.\n",
    "    - It adds the input tensors with the output of the second cnn. this addition actually tells us the difference between the input and the second cnn output. By this difference check the model have the chance to check if the residual features are retained. $output= Input + Residual$. here, residual is the difference. By adding the residual, the network \"corrects\" the output and ensures that the relevant information is preserved.\n",
    "    - The term \"shortcut\" comes from the fact that this connection provides a shortcut for the gradient during backpropagation, allowing it to flow more easily through the network. In traditional deep networks, as the number of layers increases, the gradients can diminish (vanishing gradient) or explode (exploding gradient) as they propagate backward during training. This makes training deeper networks more challenging. With the shortcut connection, the gradients during backpropagation can directly \"shortcut\" through the identity mapping (the addition operation) without being affected by the convolutional layers. The addition operation creates a \"skip connection\" that enables the gradient to flow directly from the output to the input of cnn2, effectively bypassing cnn1 and cnn3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet_Like(keras.Model):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(ResNet_Like, self).__init__()\n",
    "        self.block1 = ResBlock([32, 32, 64])\n",
    "        self.block2 = ResBlock([128, 128, 256])\n",
    "        self.block3 = ResBlock([128, 256, 512])\n",
    "        self.pool = layers.GlobalAveragePooling2D()  #layers.Flatten()\n",
    "        self.classifier = layers.Dense(num_classes)\n",
    "\n",
    "    def call(self, input_tensor, training=False):\n",
    "        x = self.block1(input_tensor, training=training)\n",
    "        x = self.block2(x, training=training)\n",
    "        x = self.block3(x, training=training)\n",
    "        x = self.pool(x, training=training)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "    def model(self):\n",
    "        x = keras.Input(shape=(28, 28, 1))\n",
    "        return keras.Model(inputs=[x], outputs=self.call(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE**\n",
    "- this is Model like ResNet, not exactly!\n",
    "- Global Average Pooling 2D reduces the spatial dimensions of the tensor to a single value per channel by averaging the values across the spatial dimensions. This is often used as an alternative to traditional flattening before the final classification layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ResNet_Like().model()\n",
    "base_input = model.layers[0].input\n",
    "base_output = model.layers[2].output\n",
    "output = layers.Dense(10)(layers.Flatten()(base_output))\n",
    "model = keras.Model(base_input, output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- model=ResNet().model() : creates an instances of ResNet and calls its model functionn. This instance represents the whole architecture.\n",
    "- base_input and base_output: retrieves the model input and output tensors.\n",
    "- output= layers.Dense(10)(layers.Flatten())(base_output): creates new output layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(),\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "938/938 - 554s - loss: 0.1052 - accuracy: 0.9671 - 554s/epoch - 591ms/step\n",
      "157/157 - 20s - loss: 0.0456 - accuracy: 0.9849 - 20s/epoch - 126ms/step\n",
      "INFO:tensorflow:Assets written to: pretrained\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: pretrained\\assets\n"
     ]
    }
   ],
   "source": [
    "model.fit(x_train, y_train, batch_size=64, epochs=1, verbose=2)\n",
    "model.evaluate(x_test, y_test, batch_size=64, verbose=2)\n",
    "model.save(\"pretrained\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
