{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I discussed earlier that **sequential model** is convenient but can't use all time. For example if we have mnist data having each image 2 output labels, in this case sequential model can't be used.Because it only works for one input to one output mapping. here comes the role of functional model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, regularizers\n",
    "from tensorflow.keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #for gpu\n",
    "# physical_devices=tf.config.list_physical_devices(\"GPU\")\n",
    "# tf.config.experimental.set_memory_growth(physical_devices[0],True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting hyperparameters\n",
    "BATCH_SIZE = 64\n",
    "WEIGHT_DECAY = 0.001\n",
    "LEARNING_RATE = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "train_df=pd.read_csv(\"data/train.csv\")\n",
    "test_df=pd.read_csv(\"data/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Image</th>\n",
       "      <th>first_num</th>\n",
       "      <th>second_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0_00.png</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100_00.png</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Image  first_num  second_num\n",
       "0    0_00.png          0           0\n",
       "1  100_00.png          0           0"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_images =  [os.path.join(\"data/train_images/\",file) for file in  train_df.iloc[:, 0].values]\n",
    "te_images = [os.path.join(\"data/test_images/\",file) for file in test_df.iloc[:, 0].values]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "in the above, getcwd() returns a string, concatenate with the relative pathe of train or test images and then appends each image filename (extracted from the first column of train_df) to form an array of file paths for training images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['data/train_images/0_00.png', 'data/train_images/100_00.png']\n",
      "64000\n",
      "(64000, 3)\n",
      "['data/test_images/0_02.png', 'data/test_images/100_02.png']\n",
      "20000\n",
      "(20000, 3)\n"
     ]
    }
   ],
   "source": [
    "print(t_images[:2])\n",
    "print(len(t_images))\n",
    "print(train_df.shape)\n",
    "\n",
    "print(te_images[:2])\n",
    "print(len(te_images))\n",
    "print(test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = train_df.iloc[:, 1:].values\n",
    "test_labels = test_df.iloc[:, 1:].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_image(image_path, label):\n",
    "    image = tf.io.read_file(image_path)\n",
    "    image = tf.image.decode_image(image, channels=1, dtype=tf.float32)\n",
    "\n",
    "    # In older versions you need to set shape in order to avoid error\n",
    "    # on newer (2.3.0+) the following 3 lines can safely be removed\n",
    "    # image.set_shape((64, 64, 1))\n",
    "    # label[0].set_shape([])\n",
    "    # label[1].set_shape([])\n",
    "\n",
    "    labels = {\"first_num\": label[0], \"second_num\": label[1]}\n",
    "    return image, labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((t_images, train_labels))\n",
    "train_dataset = (\n",
    "    train_dataset.shuffle(buffer_size=len(train_labels))\n",
    "    .map(read_image)\n",
    "    .batch(batch_size=BATCH_SIZE)\n",
    "    .prefetch(buffer_size=AUTOTUNE)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- AUTOTUNE: is a constant used to autotune the input parameters.\n",
    "- used when tf.data module\n",
    "- buffer defines how many element to shuffle\n",
    "- map: read image and assign the correct label asscociated with it\n",
    "- buffer_size=AUTOTUNE determines number of elements to be fetched. AUTOTUNE determines the optimal number automatically\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = tf.data.Dataset.from_tensor_slices((te_images, test_labels))\n",
    "test_dataset = (\n",
    "    test_dataset.map(read_image)\n",
    "    .batch(batch_size=BATCH_SIZE)\n",
    "    .prefetch(buffer_size=AUTOTUNE)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = keras.Input(shape=(64, 64, 1))\n",
    "x = layers.Conv2D(\n",
    "    filters=32,\n",
    "    kernel_size=3,\n",
    "    padding=\"same\",\n",
    "    kernel_regularizer=regularizers.l2(WEIGHT_DECAY),\n",
    ")(inputs)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = keras.activations.relu(x)\n",
    "x = layers.Conv2D(64, 3, kernel_regularizer=regularizers.l2(WEIGHT_DECAY),)(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = keras.activations.relu(x)\n",
    "x = layers.MaxPooling2D()(x)\n",
    "x = layers.Conv2D(\n",
    "    64, 3, activation=\"relu\", kernel_regularizer=regularizers.l2(WEIGHT_DECAY),\n",
    ")(x)\n",
    "x = layers.Conv2D(128, 3, activation=\"relu\")(x)\n",
    "x = layers.MaxPooling2D()(x)\n",
    "x = layers.Flatten()(x)\n",
    "x = layers.Dense(128, activation=\"relu\")(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "x = layers.Dense(64, activation=\"relu\",kernel_regularizer=regularizers.l2(.01))(x)\n",
    "output1 = layers.Dense(10, activation=\"softmax\", name=\"first_num\")(x)\n",
    "output2 = layers.Dense(10, activation=\"softmax\", name=\"second_num\")(x)\n",
    "model = keras.Model(inputs=inputs, outputs=[output1, output2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_5 (InputLayer)        [(None, 64, 64, 1)]          0         []                            \n",
      "                                                                                                  \n",
      " conv2d_16 (Conv2D)          (None, 64, 64, 32)           320       ['input_5[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_8 (Bat  (None, 64, 64, 32)           128       ['conv2d_16[0][0]']           \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " tf.nn.relu_8 (TFOpLambda)   (None, 64, 64, 32)           0         ['batch_normalization_8[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " conv2d_17 (Conv2D)          (None, 62, 62, 64)           18496     ['tf.nn.relu_8[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_9 (Bat  (None, 62, 62, 64)           256       ['conv2d_17[0][0]']           \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " tf.nn.relu_9 (TFOpLambda)   (None, 62, 62, 64)           0         ['batch_normalization_9[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " max_pooling2d_8 (MaxPoolin  (None, 31, 31, 64)           0         ['tf.nn.relu_9[0][0]']        \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv2d_18 (Conv2D)          (None, 29, 29, 64)           36928     ['max_pooling2d_8[0][0]']     \n",
      "                                                                                                  \n",
      " conv2d_19 (Conv2D)          (None, 27, 27, 128)          73856     ['conv2d_18[0][0]']           \n",
      "                                                                                                  \n",
      " max_pooling2d_9 (MaxPoolin  (None, 13, 13, 128)          0         ['conv2d_19[0][0]']           \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " flatten_4 (Flatten)         (None, 21632)                0         ['max_pooling2d_9[0][0]']     \n",
      "                                                                                                  \n",
      " dense_8 (Dense)             (None, 128)                  2769024   ['flatten_4[0][0]']           \n",
      "                                                                                                  \n",
      " dropout_4 (Dropout)         (None, 128)                  0         ['dense_8[0][0]']             \n",
      "                                                                                                  \n",
      " dense_9 (Dense)             (None, 64)                   8256      ['dropout_4[0][0]']           \n",
      "                                                                                                  \n",
      " first_num (Dense)           (None, 10)                   650       ['dense_9[0][0]']             \n",
      "                                                                                                  \n",
      " second_num (Dense)          (None, 10)                   650       ['dense_9[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 2908564 (11.10 MB)\n",
      "Trainable params: 2908372 (11.09 MB)\n",
      "Non-trainable params: 192 (768.00 Byte)\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice here we have two output labels from x. It can't be done using sequential model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(LEARNING_RATE),\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(),\n",
    "    metrics=[\"accuracy\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 - 1076s - loss: 1.7951 - first_num_loss: 0.7573 - second_num_loss: 0.7475 - first_num_accuracy: 0.7326 - second_num_accuracy: 0.7354 - 1076s/epoch - 1s/step\n",
      "Epoch 2/5\n",
      "1000/1000 - 1028s - loss: 0.5247 - first_num_loss: 0.1838 - second_num_loss: 0.1812 - first_num_accuracy: 0.9408 - second_num_accuracy: 0.9399 - 1028s/epoch - 1s/step\n",
      "Epoch 3/5\n",
      "1000/1000 - 994s - loss: 0.3738 - first_num_loss: 0.1258 - second_num_loss: 0.1228 - first_num_accuracy: 0.9595 - second_num_accuracy: 0.9587 - 994s/epoch - 994ms/step\n",
      "Epoch 4/5\n",
      "1000/1000 - 972s - loss: 0.3176 - first_num_loss: 0.1042 - second_num_loss: 0.1044 - first_num_accuracy: 0.9669 - second_num_accuracy: 0.9661 - 972s/epoch - 972ms/step\n",
      "Epoch 5/5\n",
      "1000/1000 - 990s - loss: 0.2762 - first_num_loss: 0.0894 - second_num_loss: 0.0871 - first_num_accuracy: 0.9713 - second_num_accuracy: 0.9715 - 990s/epoch - 990ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1e3e666f010>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_dataset, batch_size=BATCH_SIZE, epochs=5, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 - 216s - loss: 0.8706 - first_num_loss: 0.2268 - second_num_loss: 0.5487 - first_num_accuracy: 0.9333 - second_num_accuracy: 0.8529 - 216s/epoch - 690ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.8705901503562927,\n",
       " 0.2267829328775406,\n",
       " 0.5486605167388916,\n",
       " 0.9332500100135803,\n",
       " 0.8529000282287598]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_dataset,batch_size=BATCH_SIZE, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "here the training accuracy is significantly higher than the test accuracy. Which refers to overfitting. By tweaking the regularization decay, dropout probability may be this problem will be resolved."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
